{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from nir.utils import create_filter_query_function, change_bm25_parameters\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import math\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from mmnrm.evaluation import TREC_Evaluator\n",
    "from mmnrm.utils import set_random_seed, load_model_weights, load_model\n",
    "from mmnrm.dataset import TestCollectionV2, sentence_splitter_builderV2\n",
    "from mmnrm.evaluation import BioASQ_Evaluator\n",
    "from mmnrm.modelsv2 import deep_rank\n",
    "from mmnrm.text import TREC_goldstandard_transform, TREC_queries_transform, TREC_results_transform\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import json\n",
    "\n",
    "es = Elasticsearch([\"http://193.136.175.98:8125\"])\n",
    "\n",
    "index_name = \"trec-pm-2020-synonym\"\n",
    "change_bm25_parameters(0.9, 0.7, index_name, es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "import ctypes\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_TREC_topics(topics_file, query_build):\n",
    "    with open(topics_file) as f:\n",
    "        xml_dict=xmltodict.parse(f.read())[\"topics\"][\"topic\"]\n",
    "\n",
    "    topics_json = []\n",
    "\n",
    "    for topic in xml_dict:\n",
    "        topics_json.append({\"id\":topic[\"@number\"],\n",
    "                           \"disease\":topic[\"disease\"],\n",
    "                           \"gene\":topic[\"gene\"],\n",
    "                           \"treatment\":topic[\"treatment\"]})\n",
    "\n",
    "    return TREC_queries_transform(topics_json, number_parameter=\"id\", fn=query_build)\n",
    "\n",
    "def save_answers_to_file(answers, name):\n",
    "\n",
    "    \n",
    "    with open(name,\"w\", encoding=\"utf-8\") as f:\n",
    "        for line in answers:\n",
    "            f.write(line+\"\\n\")\n",
    "        \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_queries(queries, top_k=1000):\n",
    "    filter_query_string = create_filter_query_function()\n",
    "\n",
    "    documents = {}\n",
    "\n",
    "    for j,query_data in enumerate(queries):\n",
    "\n",
    "        if not j%10:\n",
    "            print(j, end=\"\\r\")\n",
    "\n",
    "        query = filter_query_string(query_data[\"query\"])\n",
    "        query_es = {\n",
    "                  \"query\": {\n",
    "                    \"bool\": {\n",
    "                      \"must\": [\n",
    "                        {\n",
    "                          \"query_string\": {\n",
    "                            \"query\": query, \n",
    "                            \"analyzer\": \"english\",\n",
    "                            \"fields\": [\"text\"]\n",
    "                          }\n",
    "                        }\n",
    "                      ], \n",
    "                      \"filter\": [], \n",
    "                      \"should\": [], \n",
    "                      \"must_not\": []\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "        retrieved = es.search(index=index_name, body=query_es, size=top_k, request_timeout=200)\n",
    "\n",
    "        documents[query_data[\"id\"]] = list(map(lambda x:{\"id\":x[\"_source\"][\"id\"], \n",
    "                                                         \"text\":x[\"_source\"][\"text\"],\n",
    "                                                         \"title\":x[\"_source\"][\"title\"],\n",
    "                                                         \"score\":x['_score']}, retrieved['hits']['hits']))\n",
    "\n",
    "        # just to ensure the elastic search order is mantained\n",
    "        validate_order = lambda x:all(x[i] >= x[i+1] for i in range(len(x)-1))\n",
    "        assert validate_order(list(map(lambda x: x['_score'], retrieved['hits']['hits'])))\n",
    "        \n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topics\n",
    "topics = load_TREC_topics(\"topics2020.xml\", lambda x:x[\"treatment\"]+\" \"+x[\"disease\"]+\" \"+x[\"gene\"])\n",
    "#topics = load_TREC_topics(\"topics2020.xml\", lambda x:\"Is {} effective for treatment of {} {}\".format(x[\"treatment\"],x[\"disease\"],x[\"gene\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\r"
     ]
    }
   ],
   "source": [
    "retrieved = execute_queries(topics)\n",
    "\n",
    "tag = \"BIT.UA-baseline\"\n",
    "\n",
    "answers = []\n",
    "for q in topics:\n",
    "    \n",
    "    for j,doc_info in enumerate(retrieved[q[\"id\"]]):\n",
    "        answers.append(\"{} Q0 {} {} {} {}\".format(q[\"id\"],\n",
    "                                         doc_info[\"id\"],\n",
    "                                         j+1,\n",
    "                                         doc_info[\"score\"],\n",
    "                                         tag))\n",
    "\n",
    "save_answers_to_file(answers, \"BIT.UA-baseline.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trec_evaluator = TREC_Evaluator(\"qrels-treceval-abstracts.2019.txt\", '/backup/TREC/TestSet/trec_eval-9.0.7/trec_eval')\n",
    "#test_collection = TestCollectionV2(topics, retrieved, trec_evaluator).batch_size(100)\n",
    "\n",
    "#output_metrics=[\"recall_100\",\"recall_500\",\"recall_1000\", \"map_cut_1000\", \"ndcg_cut_10\", \"P_5\"]\n",
    "#metrics = test_collection.evaluate_pre_rerank(output_metris=output_metrics)\n",
    "\n",
    "#[ (m, metrics[m]) for m in output_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#change query\n",
    "topics = load_TREC_topics(\"topics2020.xml\", lambda x:\"Is {} effective for treatment of {} {}\".format(x[\"treatment\"],x[\"disease\"],x[\"gene\"],x[\"gene\"]))\n",
    "\n",
    "trec_evaluator = TREC_Evaluator(None, '/backup/TREC/TestSet/trec_eval-9.0.7/trec_eval')\n",
    "test_collection = TestCollectionV2(topics, retrieved, trec_evaluator).batch_size(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '1',\n",
       "  'query': 'Is Regorafenib effective for treatment of colorectal cancer ABL1'},\n",
       " {'id': '2',\n",
       "  'query': 'Is Alectinib effective for treatment of non-small cell carcinoma ALK'},\n",
       " {'id': '3',\n",
       "  'query': 'Is Gilteritinib effective for treatment of acute myeloid leukemia ALK'},\n",
       " {'id': '4',\n",
       "  'query': 'Is Binimetinib effective for treatment of melanoma BRAF'},\n",
       " {'id': '5',\n",
       "  'query': 'Is Sorafenib effective for treatment of hepatocellular carcinoma BRAF'},\n",
       " {'id': '6',\n",
       "  'query': 'Is Carboplatin effective for treatment of ovarian carcinoma BRCA1'},\n",
       " {'id': '7',\n",
       "  'query': 'Is Olaparib effective for treatment of ovarian cancer BRCA1'},\n",
       " {'id': '8',\n",
       "  'query': 'Is Rucaparib effective for treatment of ovarian cancer BRCA1'},\n",
       " {'id': '9',\n",
       "  'query': 'Is Carboplatin effective for treatment of ovarian carcinoma BRCA2'},\n",
       " {'id': '10',\n",
       "  'query': 'Is Olaparib effective for treatment of ovarian cancer BRCA2'},\n",
       " {'id': '11',\n",
       "  'query': 'Is Abemaciclib effective for treatment of breast cancer CDK4'},\n",
       " {'id': '12',\n",
       "  'query': 'Is Abemaciclib effective for treatment of breast cancer CDK6'},\n",
       " {'id': '13',\n",
       "  'query': 'Is Abemaciclib effective for treatment of breast cancer CDKN2A'},\n",
       " {'id': '14',\n",
       "  'query': 'Is Ribociclib effective for treatment of breast cancer CDKN2A'},\n",
       " {'id': '15',\n",
       "  'query': 'Is Afatinib effective for treatment of non-small cell lung cancer EGFR'},\n",
       " {'id': '16',\n",
       "  'query': 'Is Osimertinib effective for treatment of non-small cell lung cancer EGFR'},\n",
       " {'id': '17',\n",
       "  'query': 'Is Afatinib effective for treatment of non-small cell lung cancer ERBB2'},\n",
       " {'id': '18',\n",
       "  'query': 'Is Temsirolimus effective for treatment of renal cell carcinoma ERBB2'},\n",
       " {'id': '19',\n",
       "  'query': 'Is Erdafitinib effective for treatment of urothelial carcinoma FGFR1'},\n",
       " {'id': '20',\n",
       "  'query': 'Is Sorafenib effective for treatment of hepatocellular carcinoma FGFR1'},\n",
       " {'id': '21',\n",
       "  'query': 'Is Lenvatinib effective for treatment of differentiated thyroid carcinoma FGFR2'},\n",
       " {'id': '22',\n",
       "  'query': 'Is Ibrutinib effective for treatment of mantle cell lymphoma FLT3'},\n",
       " {'id': '23',\n",
       "  'query': 'Is Vandetanib effective for treatment of medullary thyroid cancer FLT3'},\n",
       " {'id': '24',\n",
       "  'query': 'Is Ivosidenib effective for treatment of acute myeloid leukemia IDH1'},\n",
       " {'id': '25',\n",
       "  'query': 'Is Ziv-Aflibercept effective for treatment of colorectal cancer KDR'},\n",
       " {'id': '26',\n",
       "  'query': 'Is Pazopanib effective for treatment of renal cell carcinoma KIT'},\n",
       " {'id': '27',\n",
       "  'query': 'Is Sorafenib effective for treatment of renal cell carcinoma KIT'},\n",
       " {'id': '28',\n",
       "  'query': 'Is Trametinib effective for treatment of melanoma KRAS'},\n",
       " {'id': '29',\n",
       "  'query': 'Is Crizotinib effective for treatment of non-small cell lung cancer MET'},\n",
       " {'id': '30',\n",
       "  'query': 'Is Regorafenib effective for treatment of colorectal cancer NTRK1'},\n",
       " {'id': '31',\n",
       "  'query': 'Is Sorafenib effective for treatment of hepatocellular carcinoma NTRK2'},\n",
       " {'id': '32',\n",
       "  'query': 'Is Olaratumab effective for treatment of soft tissue sarcoma PDGFRA'},\n",
       " {'id': '33',\n",
       "  'query': 'Is Temsirolimus effective for treatment of renal cell carcinoma PIK3CA'},\n",
       " {'id': '34',\n",
       "  'query': 'Is Copanlisib effective for treatment of follicular lymphoma PIK3R1'},\n",
       " {'id': '35',\n",
       "  'query': 'Is Vismodegib effective for treatment of basal cell carcinoma PTCH1'},\n",
       " {'id': '36',\n",
       "  'query': 'Is Duvelisib effective for treatment of chronic lymphocytic leukemia PTEN'},\n",
       " {'id': '37',\n",
       "  'query': 'Is Binimetinib effective for treatment of melanoma PTPN11'},\n",
       " {'id': '38',\n",
       "  'query': 'Is Ibrutinib effective for treatment of mantle cell lymphoma RET'},\n",
       " {'id': '39',\n",
       "  'query': 'Is Entrectinib effective for treatment of non-small cell lung cancer ROS1'},\n",
       " {'id': '40',\n",
       "  'query': 'Is Glasdegib effective for treatment of acute myeloid leukemia SMO'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliar function\n",
    "\n",
    "def load_neural_model(path_to_weights):\n",
    "    \n",
    "    rank_model = load_model(path_to_weights, change_config={\"return_snippets_score\":True})\n",
    "    tk = rank_model.tokenizer\n",
    "    \n",
    "    model_cfg = rank_model.savable_config[\"model\"]\n",
    "    \n",
    "    max_input_query = model_cfg[\"max_q_length\"]\n",
    "    max_input_sentence = model_cfg[\"max_s_length\"]\n",
    "    max_s_per_q_term = model_cfg[\"max_s_per_q_term\"]\n",
    "    \n",
    "    # redundant code... replace\n",
    "    max_sentences_per_query = model_cfg[\"max_s_per_q_term\"]\n",
    "\n",
    "    pad_query = lambda x, dtype='int32': tf.keras.preprocessing.sequence.pad_sequences(x, \n",
    "                                                                                       maxlen=max_input_query,\n",
    "                                                                                       dtype=dtype, \n",
    "                                                                                       padding='post', \n",
    "                                                                                       truncating='post', \n",
    "                                                                                       value=0)\n",
    "\n",
    "    pad_sentences = lambda x, dtype='int32': tf.keras.preprocessing.sequence.pad_sequences(x, \n",
    "                                                                                           maxlen=max_input_sentence,\n",
    "                                                                                           dtype=dtype, \n",
    "                                                                                           padding='post', \n",
    "                                                                                           truncating='post', \n",
    "                                                                                           value=0)\n",
    "\n",
    "    pad_docs = lambda x, max_lim, dtype='int32': x[:max_lim] + [[]]*(max_lim-len(x))\n",
    "\n",
    "    idf_from_id_token = lambda x: math.log(tk.document_count/tk.word_docs[tk.index_word[x]])\n",
    "\n",
    "    train_sentence_generator, test_sentence_generator = sentence_splitter_builderV2(tk, \n",
    "                                                                                      max_sentence_size=max_input_sentence,\n",
    "                                                                                      mode=4)\n",
    "\n",
    "\n",
    "    def test_input_generator(data_generator):\n",
    "\n",
    "        data_generator = test_sentence_generator(data_generator)\n",
    "\n",
    "        for _id, query, docs in data_generator:\n",
    "\n",
    "            # tokenization\n",
    "            query_idf = list(map(lambda x: idf_from_id_token(x), query))\n",
    "\n",
    "            tokenized_docs = []\n",
    "            ids_docs = []\n",
    "            offsets_docs = []\n",
    "            for doc in docs:\n",
    "\n",
    "                padded_doc = pad_docs(doc[\"text\"], max_lim=max_input_query)\n",
    "                for q in range(len(padded_doc)):\n",
    "                    padded_doc[q] = pad_docs(padded_doc[q], max_lim=max_sentences_per_query)\n",
    "                    padded_doc[q] = pad_sentences(padded_doc[q])\n",
    "                tokenized_docs.append(padded_doc)\n",
    "                ids_docs.append(doc[\"id\"])\n",
    "                offsets_docs.append(doc[\"offset\"])\n",
    "\n",
    "            # padding\n",
    "            query = pad_query([query])[0]\n",
    "            query = [query] * len(tokenized_docs)\n",
    "            query_idf = pad_query([query_idf], dtype=\"float32\")[0]\n",
    "            query_idf = [query_idf] * len(tokenized_docs)\n",
    "\n",
    "            yield _id, [np.array(query), np.array(tokenized_docs), np.array(query_idf)], ids_docs, offsets_docs\n",
    "    \n",
    "    return rank_model, test_input_generator\n",
    "\n",
    "def rank(model, t_collection):\n",
    "\n",
    "    generator_Y = t_collection.generator()\n",
    "                \n",
    "    q_scores = defaultdict(list)\n",
    "\n",
    "    for i, _out in enumerate(generator_Y):\n",
    "        query_id, Y, docs_info, offsets_docs = _out\n",
    "        s_time = time.time()\n",
    "        \n",
    "        scores, q_sentence_attention = model.predict(Y)\n",
    "        scores = scores[:,0].tolist()\n",
    "            \n",
    "        print(\"\\rEvaluation {} | time {}\".format(i, time.time()-s_time), end=\"\\r\")\n",
    "        #q_scores[query_id].extend(list(zip(docs_ids,scores)))\n",
    "        for i in range(len(docs_info)):\n",
    "            q_scores[query_id].append((docs_info[i], scores[i], q_sentence_attention[i], offsets_docs[i]))\n",
    "\n",
    "    # sort the rankings\n",
    "    for query_id in q_scores.keys():\n",
    "        q_scores[query_id].sort(key=lambda x:-x[1])\n",
    "        q_scores[query_id] = q_scores[query_id]\n",
    "    \n",
    "    return q_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG created tokenizer bioasq_2020_RegexTokenizer\n",
      "False False\n",
      "[LOAD FROM CACHE] Load embedding matrix from /backup/NIR_BioASQ/embeddings/WORD2VEC_embedding_bioasq_gensim_iter_15_freq0_200_Regex_word2vec_bioasq_2020_RegexTokenizer\n",
      "[EMBEDDING MATRIX SHAPE] (4978472, 200)\n",
      "Evaluation 399 | time 0.7395062446594238\r"
     ]
    }
   ],
   "source": [
    "#path = \"/backup/NIR_BioASQ/best_validation_models/still-butterfly-1_batch0_map\"\n",
    "#path = \"/backup/NIR_BioASQ/best_validation_models/electric-resonance-5_batch0_map\"\n",
    "path = \"trained_models/exalted-resonance-2_val_collection0_P_5\"\n",
    "\n",
    "ranking_model, test_input_generator = load_neural_model(path)\n",
    "\n",
    "test_collection.set_transform_inputs_fn(test_input_generator)\n",
    "    \n",
    "result = rank(ranking_model, test_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BIT.UA-nn-run3.txt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag = \"BIT.UA-nn-run3\"\n",
    "\n",
    "answers = []\n",
    "for q in topics:\n",
    "    \n",
    "    for j,doc_info in enumerate(result[q[\"id\"]]):\n",
    "        answers.append(\"{} Q0 {} {} {} {}\".format(q[\"id\"],\n",
    "                                         doc_info[0],\n",
    "                                         j+1,\n",
    "                                         doc_info[1],\n",
    "                                         tag))\n",
    "\n",
    "save_answers_to_file(answers, \"BIT.UA-nn-run3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove /tmp/tmp5zoadnnf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('recall_100', 0.3264),\n",
       " ('recall_500', 0.58),\n",
       " ('recall_1000', 0.6523),\n",
       " ('map_cut_1000', 0.2314),\n",
       " ('ndcg_cut_10', 0.5105),\n",
       " ('P_5', 0.56)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output_metrics=[\"recall_100\",\"recall_500\",\"recall_1000\", \"map_cut_1000\", \"ndcg_cut_10\", \"P_5\"]\n",
    "#metrics = test_collection.evaluate(result)\n",
    "#[ (m, metrics[m]) for m in output_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove /tmp/tmp_t12qp0c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('recall_100', 0.3461),\n",
       " ('recall_500', 0.5907),\n",
       " ('recall_1000', 0.6523),\n",
       " ('map_cut_1000', 0.2547),\n",
       " ('ndcg_cut_10', 0.5321),\n",
       " ('P_5', 0.59)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_metrics=[\"recall_100\",\"recall_500\",\"recall_1000\", \"map_cut_1000\", \"ndcg_cut_10\", \"P_5\"]\n",
    "metrics = test_collection.evaluate(result)\n",
    "[ (m, metrics[m]) for m in output_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove /tmp/tmpwxqlnfq7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('recall_100', 0.1529),\n",
       " ('recall_500', 0.5085),\n",
       " ('recall_1000', 0.7916),\n",
       " ('map_cut_1000', 0.1349),\n",
       " ('ndcg_cut_10', 0.2653),\n",
       " ('P_5', 0.33)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_metrics=[\"recall_100\",\"recall_500\",\"recall_1000\", \"map_cut_1000\", \"ndcg_cut_10\", \"P_5\"]\n",
    "metrics = test_collection.evaluate(result)\n",
    "[ (m, metrics[m]) for m in output_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow2Wnir",
   "language": "python",
   "name": "tensor2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
