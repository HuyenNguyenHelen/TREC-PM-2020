{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from nir.utils import create_filter_query_function, change_bm25_parameters\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from mmnrm.utils import set_random_seed\n",
    "from mmnrm.dataset import TestCollectionV2, TrainPairwiseCollection\n",
    "from mmnrm.text import TREC_goldstandard_transform, TREC_queries_transform, TREC_results_transform\n",
    "from mmnrm.evaluation import TREC_Evaluator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import os \n",
    "import sys\n",
    "\n",
    "from utils import collection_iterator\n",
    "\n",
    "set_random_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def load_TREC_qrels(q_rels_file, test_ids):\n",
    "    \n",
    "    with open(q_rels_file) as f:\n",
    "        goldstandard = defaultdict(list)\n",
    "\n",
    "        for line in f:\n",
    "            line = line.strip().split(\" \")\n",
    "            try:\n",
    "                if line[0] in test_ids:\n",
    "                    continue\n",
    "                goldstandard[line[0]].append((line[2], line[3]))\n",
    "            except :\n",
    "                print(line)\n",
    "            \n",
    "    return TREC_goldstandard_transform(goldstandard)\n",
    "\n",
    "\n",
    "import xmltodict\n",
    "import ctypes\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_TREC_topics(topics_file, test_ids):\n",
    "    with open(topics_file) as f:\n",
    "        xml_dict=xmltodict.parse(f.read())[\"topics\"][\"topic\"]\n",
    "\n",
    "    topics_train_json = []\n",
    "    topics_test_json = []\n",
    "    \n",
    "    for topic in xml_dict:\n",
    "        if topic[\"@number\"] in test_ids:\n",
    "            topics_test_json.append({\"id\":topic[\"@number\"],\n",
    "                           \"disease\":topic[\"disease\"],\n",
    "                           \"gene\":topic[\"gene\"],\n",
    "                           \"demographic\":topic[\"demographic\"]})\n",
    "        else:\n",
    "            topics_train_json.append({\"id\":topic[\"@number\"],\n",
    "                           \"disease\":topic[\"disease\"],\n",
    "                           \"gene\":topic[\"gene\"],\n",
    "                           \"demographic\":topic[\"demographic\"]})\n",
    "        \n",
    "    train = TREC_queries_transform(topics_train_json, number_parameter=\"id\", fn=lambda x:\"What is the treatment for \" + x[\"disease\"]+\" \"+x[\"gene\"])\n",
    "    test = TREC_queries_transform(topics_test_json, number_parameter=\"id\", fn=lambda x:\"What is the treatment for \" + x[\"disease\"]+\" \"+x[\"gene\"])\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = set(map(lambda x:str(x), random.sample(list(range(1,41)),k=10)))\n",
    "\n",
    "train_topics, test_topics = load_TREC_topics(\"topics2019.xml\", test_ids)\n",
    "goldstandard = load_TREC_qrels(\"qrels-treceval-abstracts.2019.txt\", test_ids)\n",
    "\n",
    "zipped_collection = \"/backup/TREC-PM/Corpus/collection-json.tar.gz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '3',\n",
       "  'query': 'What is the treatment for prostate cancer ATM deletion'},\n",
       " {'id': '7',\n",
       "  'query': 'What is the treatment for non-small cell lung cancer EGFR (T790M)'},\n",
       " {'id': '10',\n",
       "  'query': 'What is the treatment for mucosal melanoma KIT (L576P), KIT amplification'},\n",
       " {'id': '12',\n",
       "  'query': 'What is the treatment for inflammatory myofibroblastic tumor RANBP2-ALK fusion'},\n",
       " {'id': '16',\n",
       "  'query': 'What is the treatment for papillary thyroid carcinoma BRAF (V600E)'},\n",
       " {'id': '18',\n",
       "  'query': 'What is the treatment for lung adenocarcinoma SND1-BRAF fusion'},\n",
       " {'id': '19',\n",
       "  'query': 'What is the treatment for colon cancer ERBB2 amplification'},\n",
       " {'id': '20', 'query': 'What is the treatment for pancreatic cancer BRCA2'},\n",
       " {'id': '27',\n",
       "  'query': 'What is the treatment for non-small cell lung cancer KRAS (G12C)'},\n",
       " {'id': '30', 'query': 'What is the treatment for endometrial cancer PIK3R1'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CORPORA] Openning tar file /backup/TREC-PM/Corpus/collection-json.tar.gz\n",
      "[CORPORA] Openning tar file tmp/tmpvcyemaof/TREC-PM-baseline-00000000-to-06000000\n",
      "[CORPORA] Openning tar file tmp/tmpvcyemaof/TREC-PM-baseline-06000000-to-12000000\n",
      "[CORPORA] Openning tar file tmp/tmpvcyemaof/TREC-PM-baseline-12000000-to-18000000\n",
      "[CORPORA] Openning tar file tmp/tmpvcyemaof/TREC-PM-baseline-18000000-to-24000000\n",
      "[CORPORA] Openning tar file tmp/tmpvcyemaof/TREC-PM-baseline-24000000-to-29138919\n"
     ]
    }
   ],
   "source": [
    "unique_pmid = set()\n",
    "skipped = 0\n",
    "articles = {}\n",
    "for article_subset in collection_iterator(zipped_collection):\n",
    "    for article in article_subset:\n",
    "\n",
    "        #skip empty abstracts\n",
    "        if article[\"abstract\"]==\"\":\n",
    "            skipped+=1\n",
    "            continue\n",
    "\n",
    "        if article[\"id\"] in unique_pmid:\n",
    "            continue\n",
    "\n",
    "        unique_pmid.add(article[\"id\"])\n",
    "        articles[article[\"id\"]] = {\"id\": article[\"id\"],\n",
    "                                   \"text\": article[\"title\"]+\" \"+article[\"abstract\"],\n",
    "                                   \"title\": article[\"title\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the goldstandard\n",
    "for q_id in goldstandard.keys():\n",
    "    for r in goldstandard[q_id].keys():\n",
    "        goldstandard[q_id][r] = list(filter(lambda x: x in articles, goldstandard[q_id][r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_collection = TrainPairwiseCollection(train_topics, goldstandard, articles).batch_size(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "2293 5453\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(train_collection.query_sampling_strategy)\n",
    "\n",
    "train_collection.set_query_sampling_strategy(2)\n",
    "print(train_collection.query_sampling_strategy)\n",
    "train_collection.batch_size(100000)\n",
    "c = Counter(next(train_collection.generator())[0])\n",
    "\n",
    "print(min(c.values()), max(c.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_collection.save(\"train_data_2019\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from nir.utils import create_filter_query_function, change_bm25_parameters\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import math\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from mmnrm.evaluation import TREC_Evaluator\n",
    "from mmnrm.utils import set_random_seed, load_model_weights, load_model\n",
    "from mmnrm.dataset import TestCollectionV2, sentence_splitter_builderV2\n",
    "from mmnrm.evaluation import BioASQ_Evaluator\n",
    "from mmnrm.modelsv2 import deep_rank\n",
    "from mmnrm.text import TREC_goldstandard_transform, TREC_queries_transform, TREC_results_transform\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "es = Elasticsearch([\"http://193.136.175.98:8125\"])\n",
    "\n",
    "index_name = \"trec-pm-2020-synonym\"\n",
    "\n",
    "def execute_queries(queries, top_k=1000):\n",
    "    filter_query_string = create_filter_query_function()\n",
    "\n",
    "    documents = {}\n",
    "\n",
    "    for j,query_data in enumerate(queries):\n",
    "\n",
    "        if not j%10:\n",
    "            print(j, end=\"\\r\")\n",
    "\n",
    "        query = filter_query_string(query_data[\"query\"])\n",
    "        query_es = {\n",
    "                  \"query\": {\n",
    "                    \"bool\": {\n",
    "                      \"must\": [\n",
    "                        {\n",
    "                          \"query_string\": {\n",
    "                            \"query\": query, \n",
    "                            \"analyzer\": \"english\",\n",
    "                            \"fields\": [\"text\"]\n",
    "                          }\n",
    "                        }\n",
    "                      ], \n",
    "                      \"filter\": [], \n",
    "                      \"should\": [], \n",
    "                      \"must_not\": []\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "        retrieved = es.search(index=index_name, body=query_es, size=top_k, request_timeout=200)\n",
    "\n",
    "        documents[query_data[\"id\"]] = list(map(lambda x:{\"id\":x[\"_source\"][\"id\"], \n",
    "                                                         \"text\":x[\"_source\"][\"text\"],\n",
    "                                                         \"title\":x[\"_source\"][\"title\"],\n",
    "                                                         \"score\":x['_score']}, retrieved['hits']['hits']))\n",
    "\n",
    "        # just to ensure the elastic search order is mantained\n",
    "        validate_order = lambda x:all(x[i] >= x[i+1] for i in range(len(x)-1))\n",
    "        assert validate_order(list(map(lambda x: x['_score'], retrieved['hits']['hits'])))\n",
    "        \n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\r"
     ]
    }
   ],
   "source": [
    "retrieved = execute_queries(test_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_evaluator = TREC_Evaluator(\"qrels-treceval-abstracts.2019.txt\", '/backup/TREC/TestSet/trec_eval-9.0.7/trec_eval')\n",
    "test_collection = TestCollectionV2(test_topics, retrieved, trec_evaluator).batch_size(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_collection.save(\"test_data_2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow2Wnir",
   "language": "python",
   "name": "tensor2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
