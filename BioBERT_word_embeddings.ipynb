{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BioBERT_word-embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPE5sVhCoUziRqhut/95wNm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenNguyenHelen/TREC-PM-2020/blob/master/BioBERT_word_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODlr2qmKJML9"
      },
      "source": [
        "## Loading processed query and documents \n",
        "- processed query file: given by either using ngram tokenization, metamap extraction, keyword extraction, named entity recognition\n",
        "- processed documents given by either metamap extraction, keyword extraction, named entity recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QA3uGYiJ943"
      },
      "source": [
        "#### Query: keyword expansion\n",
        "#### Doc: ngram tokenization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIvZYG2gKUli"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "ulUoJs1BJKUV",
        "outputId": "a23ca84e-9175-40f8-b139-1547db95df6e"
      },
      "source": [
        "with open (r'/content/PRF_kwExtraction_Query2016_1-3gram.csv', 'r', encoding = 'cp1252') as f:\n",
        "  queries = pd.read_csv(f)\n",
        "queries.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>queryID</th>\n",
              "      <th>summary</th>\n",
              "      <th>summary_keyword</th>\n",
              "      <th>description</th>\n",
              "      <th>description_keyword</th>\n",
              "      <th>note</th>\n",
              "      <th>note_keyword</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>A 78 year old male presents with frequent stoo...</td>\n",
              "      <td>{'male': 0.29736558256021506, 'presents': 0.29...</td>\n",
              "      <td>78 M transferred to nursing home for rehab aft...</td>\n",
              "      <td>{'approximately': 0.3881970960906714, 'melanot...</td>\n",
              "      <td>78 M w/ pmh of CABG in early [**Month (only...</td>\n",
              "      <td>{'nursing': 0.16048483002786335, 'home': 0.160...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>An elderly female with past medical history of...</td>\n",
              "      <td>{'elderly': 0.15831692877998726, 'female': 0.1...</td>\n",
              "      <td>An elderly female with past medical history of...</td>\n",
              "      <td>{'elderly': 0.16383273847958243, 'female': 0.1...</td>\n",
              "      <td>Ms [**Known patient lastname 241**] is a [*...</td>\n",
              "      <td>{'hyperlipidemia': 0.14664469725594667, 'Ortho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>A 75F found to be hypoglycemic with hypotensio...</td>\n",
              "      <td>{'leukocytosis': 0.5590855488092952, 'creatini...</td>\n",
              "      <td>A 75F with a PMHx significant for severe PVD, ...</td>\n",
              "      <td>{'hypotension and confusion': 0.18857126108325...</td>\n",
              "      <td>Pt is a 75F with a PMHx significant for sev...</td>\n",
              "      <td>{'unresponsive at home': 0.16805088855153935, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                       note_keyword\n",
              "0           0  ...  {'nursing': 0.16048483002786335, 'home': 0.160...\n",
              "1           1  ...  {'hyperlipidemia': 0.14664469725594667, 'Ortho...\n",
              "2           2  ...  {'unresponsive at home': 0.16805088855153935, ...\n",
              "\n",
              "[3 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYyyPC55jzlZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48d6b95f-af2b-4545-cce2-25d685e84181"
      },
      "source": [
        "queries.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "AqJSl7x0LZpi",
        "outputId": "f8af96ed-13bc-4acb-e75c-f1c4338cbdb7"
      },
      "source": [
        "with open (r'/content/ngram_token_brief_titles.csv', 'r', encoding = 'utf-8') as f:\n",
        "  docs = pd.read_csv(f)\n",
        "docs.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>queryID</th>\n",
              "      <th>brief_title</th>\n",
              "      <th>ngrams_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Dabrafenib and Trametinib in Treating Patients...</td>\n",
              "      <td>['Dabrafenib', 'and', 'Trametinib', 'in', 'Tre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Dabrafenib and Trametinib in Treating Patients...</td>\n",
              "      <td>['Dabrafenib', 'and', 'Trametinib', 'in', 'Tre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Functionality of an 8-Channel Paddle Coil for ...</td>\n",
              "      <td>['Functionality', 'of', 'an', '8-Channel', 'Pa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                      ngrams_tokens\n",
              "0           0  ...  ['Dabrafenib', 'and', 'Trametinib', 'in', 'Tre...\n",
              "1           1  ...  ['Dabrafenib', 'and', 'Trametinib', 'in', 'Tre...\n",
              "2           2  ...  ['Functionality', 'of', 'an', '8-Channel', 'Pa...\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhxa_F-Qj6gZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "513193c9-a8b5-4438-94f4-644e9f352531"
      },
      "source": [
        "docs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd6YusKRg7-G",
        "outputId": "d4033546-44bd-4219-b8ac-fe801dacd424"
      },
      "source": [
        "!pip install biobert-embedding==0.1.2\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting biobert-embedding==0.1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/d2/f0/f5bd3fd4a0bcef4d85e5e82347ae73d376d68dc8086afde75838ba0473a2/biobert-embedding-0.1.2.tar.gz\n",
            "Collecting torch==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/65/5248be50c55ab7429dd5c11f5e2f9f5865606b80e854ca63139ad1a584f2/torch-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (748.9MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9MB 23kB/s \n",
            "\u001b[?25hCollecting pytorch-pretrained-bert==0.6.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 56.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from biobert-embedding==0.1.2) (2.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.2.0->biobert-embedding==0.1.2) (1.19.5)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/e1/1b164502f455035def771ec7a31f705351b7f953695d57ce26219aaf21a9/boto3-1.17.90-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 45.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.2) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.2) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.2) (2.23.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (1.1.2)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (3.1.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (0.12.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (2.5.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (2.5.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (1.34.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (3.12.4)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (3.7.4.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (1.12)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (0.4.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (1.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (1.12.1)\n",
            "Collecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.4MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.90\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/ac/617d3ac25ea905279deb06edd82d6c19ca272006d6dcf232b837b75c3dde/botocore-1.20.90-py2.py3-none-any.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 31.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.2) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.2) (3.0.4)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow->biobert-embedding==0.1.2) (1.5.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (1.30.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (57.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.90->boto3->pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.2) (2.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (4.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (3.1.0)\n",
            "Building wheels for collected packages: biobert-embedding\n",
            "  Building wheel for biobert-embedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for biobert-embedding: filename=biobert_embedding-0.1.2-cp37-none-any.whl size=5701 sha256=35869baf4e0cd0077dfb33832cbc3dfc15907f26b097bfe9e3a8d7528548de60\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/15/65/3fc6192a7cb7920672bb46d566173decb0875f35bbe03cd09d\n",
            "Successfully built biobert-embedding\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.20.90 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert, biobert-embedding\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "Successfully installed biobert-embedding-0.1.2 boto3-1.17.90 botocore-1.20.90 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.4.2 torch-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSRQPtOdDKHB"
      },
      "source": [
        "from biobert_embedding.embedding import BiobertEmbedding\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def bioBERT_topsim (query_term, doc_terms,k):\n",
        "    cos_sim = {}\n",
        "    query_vec = bioBERTfit(query_term)\n",
        "    for item in doc_terms:\n",
        "        cos_sim[item] = cal_cosine_sim(bioBERTfit(item), query_vec)\n",
        "    top_sim_terms = most_similar (cos_sim, k)\n",
        "    return top_sim_terms\n",
        "        \n",
        "def bioBERTfit(word):\n",
        "    biobert = BiobertEmbedding()\n",
        "    vec_w = biobert.word_vector(word)\n",
        "    return vec_w\n",
        "    \n",
        "def cal_cosine_sim(single_vec_query, sing_vec):\n",
        "    cosine_sim = cosine_similarity(single_vec_query[0].reshape(1, -1),sing_vec[0].reshape(1, -1))\n",
        "    return cosine_sim\n",
        "\n",
        "def most_similar(dic, k_):\n",
        "    # Sort the given array arr in reverse order.   \n",
        "    # Print the first kth largest elements\n",
        "    sort_dic = {k: v for k, v in sorted(dic.items(), key=lambda item: item[1], reverse = True)[:k_]}\n",
        "    return sort_dic\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aokYaU3D7Ee",
        "outputId": "74f19925-7f65-4966-9b2c-f90c6e06ef50"
      },
      "source": [
        "# Example\n",
        "query = 'work'\n",
        "doc_terms = ['job', 'sky', 'sweet tea', 'do', 'scientific papers', 'working', 'high performance']\n",
        "\n",
        "bioBERT_topsim (query, doc_terms, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading the biobert model, will take a minute...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'do': array([[0.829417]], dtype=float32),\n",
              " 'job': array([[0.8601637]], dtype=float32),\n",
              " 'working': array([[0.88085926]], dtype=float32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7VzNHUfNB1p"
      },
      "source": [
        "#### Fitting model into the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvvvjnyUnc50"
      },
      "source": [
        "df[\"Age + Weight\"] = add(df[\"Age\"], df[\"Weight\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkVvX2pXhTBe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "501eca3f-c74b-450e-8f2a-6e60652f4e59"
      },
      "source": [
        "import ast\n",
        "def convertFormat (txt):\n",
        "  list_for = ast.literal_eval(txt)\n",
        "  return list_for\n",
        "#columns = ['queryID','summary_keyword','ngrams_tokens']\n",
        "temp = [queries ['queryID'], queries['summary_keyword'], docs['ngrams_tokens'][:30]]\n",
        "temp_df = pd.concat(temp,axis=1)\n",
        "temp_df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>queryID</th>\n",
              "      <th>summary_keyword</th>\n",
              "      <th>ngrams_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>{'male': 0.29736558256021506, 'presents': 0.29...</td>\n",
              "      <td>['Dabrafenib', 'and', 'Trametinib', 'in', 'Tre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>{'elderly': 0.15831692877998726, 'female': 0.1...</td>\n",
              "      <td>['Dabrafenib', 'and', 'Trametinib', 'in', 'Tre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>{'leukocytosis': 0.5590855488092952, 'creatini...</td>\n",
              "      <td>['Functionality', 'of', 'an', '8-Channel', 'Pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>{'woman': 0.15831692877998726, 'anxiety': 0.15...</td>\n",
              "      <td>['Patients', 'With', 'Refractory', 'Metastatic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>{'multiple': 0.15831692877998726, 'chronic': 0...</td>\n",
              "      <td>['HPV', 'Self-Test', 'Intervention', 'in', 'Oh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   queryID  ...                                      ngrams_tokens\n",
              "0        1  ...  ['Dabrafenib', 'and', 'Trametinib', 'in', 'Tre...\n",
              "1        2  ...  ['Dabrafenib', 'and', 'Trametinib', 'in', 'Tre...\n",
              "2        3  ...  ['Functionality', 'of', 'an', '8-Channel', 'Pa...\n",
              "3        4  ...  ['Patients', 'With', 'Refractory', 'Metastatic...\n",
              "4        5  ...  ['HPV', 'Self-Test', 'Intervention', 'in', 'Oh...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj-NO8YbsjCS"
      },
      "source": [
        "temp_df['summary_keyword'] = temp_df[['summary_keyword']].applymap(convertFormat) \n",
        "temp_df['ngrams_tokens'] = temp_df[['ngrams_tokens']].applymap(convertFormat) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xDLKrxdM_lN"
      },
      "source": [
        "def topSimTerm(q,d,k):\n",
        "  term_top_sim = {}\n",
        "  for term in q.keys():\n",
        "    term_top_sim[term] = bioBERT_topsim (term, d,k)\n",
        "  return term_top_sim\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJkxW8rAxjXQ"
      },
      "source": [
        "q={'male': 0.29736558256021506, 'presents': 0.29736558256021506, 'frequent': 0.29736558256021506, 'stools': 0.29736558256021506, 'year': 0.15831692877998726, 'melena': 0.15831692877998726, 'male presents': 0.09700399286574239, 'presents with frequent': 0.09700399286574239, 'frequent stools': 0.09700399286574239, 'year old male': 0.04940384002065631, 'stools and melena': 0.04940384002065631}\n",
        "d = ['Dabrafenib', 'and', 'Trametinib', 'in', 'Treating', 'Patients', 'With', 'Stage', 'III-IV', 'BRAF', 'Mutant', 'Melanoma', 'That', 'Can', 'not', 'Be', 'Removed', 'by', 'Surgery', 'A', 'Study', 'of', 'Fotemustine', 'FTM', 'Vs', 'FTM', 'and', 'Ipilimumab', 'IPI', 'or', 'IPI', 'and', 'Nivolumab', 'in', 'Melanoma', 'Brain', 'Metastasis', 'Study', 'to', 'Determine', 'Tolerability', 'After', 'Intravenous', 'Administration', 'of', 'BIBN', '4096', 'BS', 'in', 'Healthy', 'Male', 'and', 'Female', 'Volunteers', 'Minoxidil', '2', 'Solution', 'and', 'Botanical', 'Hair', 'Regimen', 'in', 'Women', 'With', 'Thinning', 'Hair', 'and', 'Female', 'Pattern', 'Hair', 'Loss/Androgenic', 'Alopecia', 'Bioequivalence', 'of', 'Telmisartan/Amlodipine', 'Fixed', 'Dose', 'Combination', 'Compared', 'With', 'Its', 'Monocomponents', 'in', 'Healthy', 'Male', 'and', 'Female', 'Volunteers', 'Pharmacokinetic', 'Study', 'of', 'Seresis庐', 'in', 'the', 'Skin', 'in', 'Healthy', 'Young', 'Female', 'Volunteers', 'Moletest', 'Clinical', 'Study', 'in', 'Scotland', 'Relative', 'Bioavailability', 'of', 'Ambroxol', 'Hydrochloride', 'of', 'Soft', 'Pastilles', 'Compared', 'to', 'Ambroxol', 'Hydrochloride', 'Syrup', 'in', 'Healthy', 'Male', 'and', 'Female', 'Volunteers', 'Adjuvant', 'Therapy', 'of', 'Completely', 'Resected', 'Merkel', 'Cell', 'Carcinoma', 'With', 'Immune', 'Checkpoint', 'Blocking', 'Antibodies', 'Versus', 'Observation', 'Nintedanib', 'in', 'Volunteers', 'With', 'Hepatic', 'Impairment', 'Compared', 'With', 'Healthy', 'Volunteers', 'Dabrafenib and', 'and Trametinib', 'Trametinib in', 'in Treating', 'Treating Patients', 'Patients With', 'With Stage', 'Stage III-IV', 'III-IV BRAF', 'BRAF Mutant', 'Mutant Melanoma', 'Melanoma That', 'That Can', 'Can not', 'not Be', 'Be Removed', 'Removed by', 'by Surgery', 'Surgery A', 'A Study', 'Study of', 'of Fotemustine', 'Fotemustine FTM', 'FTM Vs', 'Vs FTM', 'FTM and', 'and Ipilimumab', 'Ipilimumab IPI', 'IPI or', 'or IPI', 'IPI and', 'and Nivolumab', 'Nivolumab in', 'in Melanoma', 'Melanoma Brain', 'Brain Metastasis', 'Metastasis Study', 'Study to', 'to Determine', 'Determine Tolerability', 'Tolerability After', 'After Intravenous', 'Intravenous Administration', 'Administration of', 'of BIBN', 'BIBN 4096', '4096 BS', 'BS in', 'in Healthy', 'Healthy Male', 'Male and', 'and Female', 'Female Volunteers', 'Volunteers Minoxidil', 'Minoxidil 2', '2 Solution', 'Solution and', 'and Botanical', 'Botanical Hair', 'Hair Regimen', 'Regimen in', 'in Women', 'Women With', 'With Thinning', 'Thinning Hair', 'Hair and', 'and Female', 'Female Pattern', 'Pattern Hair', 'Hair Loss/Androgenic', 'Loss/Androgenic Alopecia', 'Alopecia Bioequivalence', 'Bioequivalence of', 'of Telmisartan/Amlodipine', 'Telmisartan/Amlodipine Fixed', 'Fixed Dose', 'Dose Combination', 'Combination Compared', 'Compared With', 'With Its', 'Its Monocomponents', 'Monocomponents in', 'in Healthy', 'Healthy Male', 'Male and', 'and Female', 'Female Volunteers', 'Volunteers Pharmacokinetic', 'Pharmacokinetic Study', 'Study of', 'of Seresis庐', 'Seresis庐 in', 'in the', 'the Skin', 'Skin in', 'in Healthy', 'Healthy Young', 'Young Female', 'Female Volunteers', 'Volunteers Moletest', 'Moletest Clinical', 'Clinical Study', 'Study in', 'in Scotland', 'Scotland Relative', 'Relative Bioavailability', 'Bioavailability of', 'of Ambroxol', 'Ambroxol Hydrochloride', 'Hydrochloride of', 'of Soft', 'Soft Pastilles', 'Pastilles Compared', 'Compared to', 'to Ambroxol', 'Ambroxol Hydrochloride', 'Hydrochloride Syrup', 'Syrup in', 'in Healthy', 'Healthy Male', 'Male and', 'and Female', 'Female Volunteers', 'Volunteers Adjuvant', 'Adjuvant Therapy', 'Therapy of', 'of Completely', 'Completely Resected', 'Resected Merkel', 'Merkel Cell', 'Cell Carcinoma', 'Carcinoma With', 'With Immune', 'Immune Checkpoint', 'Checkpoint Blocking', 'Blocking Antibodies', 'Antibodies Versus', 'Versus Observation', 'Observation Nintedanib', 'Nintedanib in', 'in Volunteers', 'Volunteers With', 'With Hepatic', 'Hepatic Impairment', 'Impairment Compared', 'Compared With', 'With Healthy', 'Healthy Volunteers', 'Dabrafenib and Trametinib', 'and Trametinib in', 'Trametinib in Treating', 'in Treating Patients', 'Treating Patients With', 'Patients With Stage', 'With Stage III-IV', 'Stage III-IV BRAF', 'III-IV BRAF Mutant', 'BRAF Mutant Melanoma', 'Mutant Melanoma That', 'Melanoma That Can', 'That Can not', 'Can not Be', 'not Be Removed', 'Be Removed by', 'Removed by Surgery', 'by Surgery A', 'Surgery A Study', 'A Study of', 'Study of Fotemustine', 'of Fotemustine FTM', 'Fotemustine FTM Vs', 'FTM Vs FTM', 'Vs FTM and', 'FTM and Ipilimumab', 'and Ipilimumab IPI', 'Ipilimumab IPI or', 'IPI or IPI', 'or IPI and', 'IPI and Nivolumab', 'and Nivolumab in', 'Nivolumab in Melanoma', 'in Melanoma Brain']\n",
        "k = 5\n",
        "topSimTerm(q,d,k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSGaDcPntNmT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "d53ce76c-b6c9-47c0-d4fb-31443a86dc58"
      },
      "source": [
        "temp_df['top_similar_terms'] = topSimTerm(temp_df['summary_keyword'],temp_df['ngrams_tokens'], 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-7b0ab258cb6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'top_similar_terms'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopSimTerm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'summary_keyword'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ngrams_tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-570872f056ac>\u001b[0m in \u001b[0;36mtopSimTerm\u001b[0;34m(q, d, k)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mterm_top_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mterm_top_sim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbioBERT_topsim\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mterm_top_sim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-89e7e60f06ea>\u001b[0m in \u001b[0;36mbioBERT_topsim\u001b[0;34m(query_term, doc_terms, k)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbioBERT_topsim\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mquery_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_terms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcos_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mquery_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbioBERTfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_term\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc_terms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcos_sim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcal_cosine_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbioBERTfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-89e7e60f06ea>\u001b[0m in \u001b[0;36mbioBERTfit\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbioBERTfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mbiobert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBiobertEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mvec_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbiobert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvec_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/biobert_embedding/embedding.py\u001b[0m in \u001b[0;36mword_vector\u001b[0;34m(self, text, handle_oov, filter_extra_tokens)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mword_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_oov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_extra_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mencoded_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_fwdprop_biobert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/biobert_embedding/embedding.py\u001b[0m in \u001b[0;36mprocess_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mmarked_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"[CLS] \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" [SEP]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Tokenize our sentence with the BERT tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarked_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsBTpZJpbL21"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}